 Tool use, whether using a stone, stick, rake, or pliers, provides an extension of the body (Van Lawick-Goodall, 1970) and involves, among other things, the transfer of a proximal movement goal for the hand into a more distal goal for the tool (Johnson and Grafton, 2003; Arbib et al., 2009). A compelling demonstration that this transfer might actually occur at the cortical level comes from neural recordings of grasping neurons in the ventral premotor cortex (PMv) and motor cortex (M1) of macaque monkeys trained to use pliers (Umilta et al., 2008). In both these areas, many neurons that encoded the specifics of hand grasping subsequently encoded tool grasping, even when use of the specific tool (reverse pliers that close as the hand grip opens) required hand kinematics opposite to those required when grasping with the hand alone. These findings suggest that tool use is supported by an effector-independent level of representation, in which the overall goal of the motor act is coded separately from the precise hand kinematics required to operate the tool. In further support of this notion, findings from human neuropsychology (Berti and Frassinetti, 2000; Maravita and Iriki, 2004), human behavior (Gentilucci et al., 2004; Cardinali et al., 2009, 2012), and macaque monkey neurophysiology (Iriki et al., 1996) suggest that following training, a tool may actually become incorporated into the body schema of the actor and coded as an extension of the hand/limb. While provocative, how well does this single mechanism explain the neural substrates of tool use in humans, particularly within established networks that have been identified for tools (Lewis, 2006), hand actions (Culham et al., 2006), and body perception (Peelen and Downing, 2007)? fMRI (3 Tesla) was used to measure the blood oxygenation level-dependent (BOLD) signal in the brains of 13 right-handed subjects (7 females; mean age: 25.7 years) during a slow event-related design with a delay interval. Subjects used either the right hand or a tool (controlled by the right hand) to execute a precision reach-to-grasp (Grasp) or reach-to-touch (Reach) movement towards a single centrally located real three-dimensional (3D) target object made of Lego blocks (Figure 1B). The tool used was a set of reverse tongs; when the hand closed on the grips, the ends of the tongs would open and vice versa. As such, different hand kinematics were required to operate the tool compared to when the hand was used alone. Use of the hand and tool were alternated across experimental runs. The position of the target object was changed between hand and tool experimental runs in order for the grasps and reaches to be performed at a comfortable distance for each effector (Figure 1B). On each trial, subjects were first cued to the action to be carried out (grasp or reach). Then, following a delay period, they performed the instructed action (with the hand or tool, depending on the experimental run). The delay timing of the paradigm allowed us to divide the trial into discrete time epochs and isolate the sustained plan-related neural responses that evolve prior to movement from the transient visual response (Preview phase) and the movement execution response (Execute phase; Figure 1C,D).10.7554/eLife.00425.003Figure 1.Experimental methods and evoked neural activity.(A) Subject setup shown from side view. (B) (Left) experimental apparatus and target object shown from the subject’s point of view for experimental runs where either the hand (top) or reverse tool (bottom) were used. The location of the target object (white block) was switched between run types but did not change its position from trial-to-trial within a imaging run. Dashed line represents the participant’s arc of reachability for each run type. In both cases (left panels), the hand is shown at its starting location. Green star with dark shadow represents the fixation LED and its location in depth. (Right) Hand and tool positions during movements performed by the subject. (C) Timing of each event-related trial. Trials began with the 3D object being illuminated while the subject maintained fixation (Preview phase; 6 s). Subjects were then instructed via headphones to perform one of two movements: Grasp the object (‘Grasp’) without lifting it or Touch the object (‘Touch’), initiating the Plan phase portion of the trial. Following a fixed delay interval (12 s), subjects were cued (by an auditory ‘beep’) to perform the instructed movement (initiating the Execute phase) and then return to the starting location. 2 s after the Go cue, vision of the workspace was extinguished and participants waited for the following trial to begin (14-s intertrial interval, ITI). (D) Averaged fMRI activity from left dorsal premotor (PMd) cortex, time-locked to trial length. MVPA was performed using single fMRI trials in two ways: 1) based on the % signal change (SC) BOLD activation evoked for each single time point in the trial (time-resolved decoding), allowing us to pinpoint when predictive movement information was available and 2) based on a windowed average of the % SC BOLD activation in the 4 s (2 imaging volumes) prior to movement initiation (denoted by the gray shaded bar).DOI: http://dx.doi.org/10.7554/eLife.00425.003 Behavioral, neuropsychological and neurophysiological evidence demonstrates that a central and governing feature of movement planning, and indeed of higher-level cognition in general, is the linking together of overarching action goals with the precise underlying kinematics required by the body to achieve those goals (Haaland et al., 2000; Andersen and Buneo, 2002; Fogassi et al., 2005; Grafton and Hamilton, 2007; Umilta et al., 2008). Exactly how the human brain supports this cognitive capacity, particularly in the everyday example of tool-use, remains poorly understood. Here we manipulated the type of object-directed hand action that was planned (grasping vs reaching) as well as the effector (hand vs tool) used to implement that action. We then employed fMRI MVPA in order to examine whether planned object-directed hand actions were represented in an effector-specific or effector-independent manner in human frontoparietal and occipitotemporal cortex. At the effector-specific level, we found that SPOC and EBA discriminated upcoming hand movements only whereas SMG and pMTG discriminated upcoming tool movements only. Furthermore, anterior parietal (post. aIPS, aIPS, t-aIPS) and motor cortex areas discriminated planned actions for both the hand and tool, but did not cross-decode between the two effectors. At the effector-independent level, in posterior parietal (pIPS and midIPS) and premotor (PMd and PMv) cortex areas, we found that the pre-movement patterns predictive of grasp vs reach actions for the hand also predicted grasp vs reach actions with the tool. Notably, because the tool-effector required very different hand kinematics than when the hand was used alone, this suggests that these brain areas encoded the action performed rather than the specific muscle movements needed to achieve it. Consistent with the transfer of goals for the hand to those of the tool, this finding resonates with embodied theories of tool use whereby through use, tools become incorporated as part of the body schema. Notably, however, in the majority of regions tested we find that neural representations remain linked to either the hand or tool. Thirteen right-handed volunteers participated in the Motor experiment (seven females; mean age: 25.7 years, age range: 20-33 years) and were recruited from the University of Western Ontario (London, Ontario, Canada). Eight of these same participants (four females) participated in a second Localizer experiment. All subjects had normal or corrected-to-normal vision and were financially compensated for their participation. Informed consent and consent to publish was obtained in accordance with ethical standards set out by the Declaration of Helsinki (1964) and with procedures approved by the University of Western Ontario’s Health Sciences Research Ethics Board (ethics review number: 13507). Subjects were naive with respect to hypothesis testing.
Sophisticated tool use is a defining characteristic of the primate species but how is it supported by the brain, particularly the human brain? Here we show, using functional MRI and pattern classification methods, that tool use is subserved by multiple distributed action-centred neural representations that are both shared with and distinct from those of the hand. In areas of frontoparietal cortex we found a common representation for planned hand- and tool-related actions. In contrast, in parietal and occipitotemporal regions implicated in hand actions and body perception we found that coding remained selectively linked to upcoming actions of the hand whereas in parietal and occipitotemporal regions implicated in tool-related processing the coding remained selectively linked to upcoming actions of the tool. The highly specialized and hierarchical nature of this coding suggests that hand- and tool-related actions are represented separately at earlier levels of sensorimotor processing before becoming integrated in frontoparietal cortex.
The use of tools is a key characteristic of primates. Chimpanzees—our closest living relatives—use sticks to probe for termites as well as stones to crack open nuts, and have even been seen using specially sharpened sticks as spear-like tools for hunting. However, despite its importance in human evolution, relatively little is known about how tool use is supported by the brain.